{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cópia de Similaridade Léxica-Sintática.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RichardTompson/BigDataPuc/blob/master/C%C3%B3pia_de_Similaridade_L%C3%A9xica_Sint%C3%A1tica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pDgXV8lvSd8"
      },
      "source": [
        "# Processamento de Linguagem Natural - Similaridade Léxica/Sintática\n",
        "\n",
        "Nesta atividade você realizará atividades práticas relacionadas a  **Similaridade léxica/sintática**, visando entender qual o seu papel nas mais diversas aplicações de PLN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDCy7V1GxQKH"
      },
      "source": [
        "##**Medidas de similaridade**\n",
        "Existe uma série de diferentes cálculos/medidas que indicam a similaridade léxica entre palavras, as chamamos de *string-based*.\n",
        "\n",
        "![String-based similarity measures](https://docs.google.com/uc?export=download&id=1iO4zT9lTIO4-XsAB-P9_BddOIJwjwMRJ)\n",
        "\n",
        "A seguir uma série de exemplos de algumas das medidas de similaridade léxica da figura acima."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRto1rHn50Q7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB_TaHIh50hq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je_iumai501N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyxAUVnG5yoG"
      },
      "source": [
        "### **Levenshtein (edit) distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMRu3cNl_7xO"
      },
      "source": [
        "A distância de Levenshtein entre duas palavras é o número mínimo de edições de um caractere (inserções, exclusões ou substituições) necessárias para alterar uma palavra pela outra. Usaremos para comparar **PALAVRAS/TOKENS**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k69kSOHL_79J"
      },
      "source": [
        "# Define 4 palavras diferentes\n",
        "p1 = \"padeiro\"\n",
        "p2 = \"pandeiro\"\n",
        "p3 = \"bombeiro\"\n",
        "p4 = \"padaria\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgPDaB-XCBYl"
      },
      "source": [
        "# Não há necessidade de implementar a função de edit distance visto que o NLTK já a implementa\n",
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXprcqetG_PL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd081d16-9188-4b2b-9c8a-a42dc99d09e2"
      },
      "source": [
        "nltk.edit_distance(p1, p2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwBEV_RuHHx4"
      },
      "source": [
        "nltk.edit_distance(p1, p3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swHvj9JFHH5n"
      },
      "source": [
        "nltk.edit_distance(p1, p4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuaJGq5WI7si",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5a51fe1-a6a0-4a15-ac55-fb9d6d318c3c"
      },
      "source": [
        "nltk.edit_distance(p3, p4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_gEpCKzES5m"
      },
      "source": [
        "### **N-grams**\n",
        "O N-grams são basicamente um conjunto de caracteres/palavras co-ocorrentes em uma determinada janela de abertura. Usaremos tanto para comparar **CARACTERES** quanto **PALAVRAS**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9Eq74Kb1aWa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d4d40fe6-f660-4f6d-b155-f3ff9e5bc0e0"
      },
      "source": [
        "# Não há necessidade de implementar uma função de n-grams - o NLTK já implementa\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "# Necessário pois utilizaremos o tokenizador\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1s3lAwk2dIk"
      },
      "source": [
        "#### N-Grams de **PALAVRAS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoFv6P1y0AHf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "7070e86a-563a-4037-8879-8b9752474eb2"
      },
      "source": [
        "# Função para gerar n-grams de palavras a partir de uma sentença.\n",
        "def extrair_ngrams_palavras(sent, n):\n",
        "    n_grams = ngrams(nltk.word_tokenize(sent, language='portuguese'), n)\n",
        "    return [ ' '.join(grams) for grams in n_grams]\n",
        " \n",
        "texto = 'Esta é uma sentença para testarmos n-grams de palavras.'\n",
        " \n",
        "print(\"1-gram: \", extrair_ngrams_palavras(texto, 1))\n",
        "print(\"2-gram: \", extrair_ngrams_palavras(texto, 2))\n",
        "print(\"3-gram: \", extrair_ngrams_palavras(texto, 3))\n",
        "print(\"4-gram: \", extrair_ngrams_palavras(texto, 4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-gram:  ['Esta', 'é', 'uma', 'sentença', 'para', 'testarmos', 'n-grams', 'de', 'palavras', '.']\n",
            "2-gram:  ['Esta é', 'é uma', 'uma sentença', 'sentença para', 'para testarmos', 'testarmos n-grams', 'n-grams de', 'de palavras', 'palavras .']\n",
            "3-gram:  ['Esta é uma', 'é uma sentença', 'uma sentença para', 'sentença para testarmos', 'para testarmos n-grams', 'testarmos n-grams de', 'n-grams de palavras', 'de palavras .']\n",
            "4-gram:  ['Esta é uma sentença', 'é uma sentença para', 'uma sentença para testarmos', 'sentença para testarmos n-grams', 'para testarmos n-grams de', 'testarmos n-grams de palavras', 'n-grams de palavras .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rpqjUaB2luu"
      },
      "source": [
        "#### N-Grams de **CARACTERES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFqLcCBK2l4M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "8795de01-4ef4-4c48-949b-2eb94b53e5ff"
      },
      "source": [
        "# Função para gerar n-grams de caracteres a partir de um texto.\n",
        "def extrair_ngrams_char(texto, n):\n",
        "  # Cria lista com caracteres\n",
        "  chars = [c for c in texto]\n",
        "  n_grams = ngrams(chars,n)\n",
        "  return [ ' '.join(grams) for grams in n_grams]\n",
        "\n",
        "texto = \"Sentença para testarmos n-grams de caracteres\"\n",
        "\n",
        "print(\"1-gram: \", extrair_ngrams_char(texto,1))\n",
        "print(\"2-gram: \", extrair_ngrams_char(texto,2))\n",
        "print(\"3-gram: \", extrair_ngrams_char(texto,3))\n",
        "print(\"4-gram: \", extrair_ngrams_char(texto,4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-gram:  ['S', 'e', 'n', 't', 'e', 'n', 'ç', 'a', ' ', 'p', 'a', 'r', 'a', ' ', 't', 'e', 's', 't', 'a', 'r', 'm', 'o', 's', ' ', 'n', '-', 'g', 'r', 'a', 'm', 's', ' ', 'd', 'e', ' ', 'c', 'a', 'r', 'a', 'c', 't', 'e', 'r', 'e', 's']\n",
            "2-gram:  ['S e', 'e n', 'n t', 't e', 'e n', 'n ç', 'ç a', 'a  ', '  p', 'p a', 'a r', 'r a', 'a  ', '  t', 't e', 'e s', 's t', 't a', 'a r', 'r m', 'm o', 'o s', 's  ', '  n', 'n -', '- g', 'g r', 'r a', 'a m', 'm s', 's  ', '  d', 'd e', 'e  ', '  c', 'c a', 'a r', 'r a', 'a c', 'c t', 't e', 'e r', 'r e', 'e s']\n",
            "3-gram:  ['S e n', 'e n t', 'n t e', 't e n', 'e n ç', 'n ç a', 'ç a  ', 'a   p', '  p a', 'p a r', 'a r a', 'r a  ', 'a   t', '  t e', 't e s', 'e s t', 's t a', 't a r', 'a r m', 'r m o', 'm o s', 'o s  ', 's   n', '  n -', 'n - g', '- g r', 'g r a', 'r a m', 'a m s', 'm s  ', 's   d', '  d e', 'd e  ', 'e   c', '  c a', 'c a r', 'a r a', 'r a c', 'a c t', 'c t e', 't e r', 'e r e', 'r e s']\n",
            "4-gram:  ['S e n t', 'e n t e', 'n t e n', 't e n ç', 'e n ç a', 'n ç a  ', 'ç a   p', 'a   p a', '  p a r', 'p a r a', 'a r a  ', 'r a   t', 'a   t e', '  t e s', 't e s t', 'e s t a', 's t a r', 't a r m', 'a r m o', 'r m o s', 'm o s  ', 'o s   n', 's   n -', '  n - g', 'n - g r', '- g r a', 'g r a m', 'r a m s', 'a m s  ', 'm s   d', 's   d e', '  d e  ', 'd e   c', 'e   c a', '  c a r', 'c a r a', 'a r a c', 'r a c t', 'a c t e', 'c t e r', 't e r e', 'e r e s']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p_NS7JG6xc3"
      },
      "source": [
        "> #### **IMPORTANTE**: Mas quais seriam algumas das aplicações dos n-grams?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfsGdk-6DNW1"
      },
      "source": [
        "#### 1) Reconhecimento de entidades / Chunking \n",
        "Imagine que você tenha um corpus (conjunto de documentos) e visualize os seguintes n-grams:\n",
        "\n",
        "1.   São Paulo (2-gram)\n",
        "2.   processamento de linguagem natural (4-gram)\n",
        "3.   o presidente alega que é inocente (6-gram)\n",
        "\n",
        "Ao fazermos um levantamento de frequência, possivelmente os exemplos 1 e 2 ocorram com mais frequência no corpus. Agora se aplicarmos um modelo de probabilidade podemos **encontrar entidades** compostas por múltiplas palavras no texto.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwNbBzdpDgvF"
      },
      "source": [
        "#### 2) Predição de palavras\n",
        "Seguindo a mesma linha anterior, é possível também utilizar os n-grams para fazer **predições de palavras**. Por exemplo, se houver a sentença parcial \"*Meu beatle favorito é*\", a probabilidade da próxima palavra ser \"*John*\", \"*Paul*\", \"*George*\" ou \"*Ringo*\" é bem maior que o restante das palavras do vocabulário. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DybjX5nsDq4i"
      },
      "source": [
        "#### 3) Correção ortográfica\n",
        "A sentença \"*beba vino*\" poderia ser corrigida para \"*beba vinho*\" se você soubesse que a palavra \"*vinho*\" tem uma alta probabilidade de ocorrência após a palavra \"*beba*\". Além disso, a sobreposição de letras entre \"*vino*\" e \"*vinho*\" é alta (i.e., baixa distância de edição)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUIhr-8wDIS0"
      },
      "source": [
        "#### 4) e por fim, nosso assunto atual, *Similaridade léxica*\n",
        "Vamos extrair 2-grams de caracteres das duas palavras a seguir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6bwpBCZMjuP"
      },
      "source": [
        "p1 = \"parar\"\n",
        "p2 = \"parado\"\n",
        "\n",
        "# 4 bi-grams - 2 únicos\n",
        "print(\"2-grams: \", extrair_ngrams_char(p1,2))\n",
        "# 5 bi-grams - 5 únicos\n",
        "print(\"2-grams: \", extrair_ngrams_char(p2,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bgzq2w2PNULy"
      },
      "source": [
        "Para **cálculo de similaridade utilizando n-grams** usamos a fórmula: `S = 2C / A + B`\n",
        "\n",
        "Onde:\n",
        "* A é o número de n-grams únicos na primeira palavra\n",
        "* B é o número de n-grams únicos na segunda palavra\n",
        "* C é o número de n-grams únicos compartilhados\n",
        "\n",
        "Portanto, neste exemplo o cálculo ficaria: `S = 2 * 2 / 2 + 5 = 0.57`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv49o9wGSsER"
      },
      "source": [
        "# Obtém os N-Grams únicos\n",
        "def uniqueNgrams(ngrams):\n",
        "    \n",
        "  ngrams = [item for item in ngrams if ngrams.count(item) == 1]\n",
        "    \n",
        "  return ngrams\n",
        "\n",
        "# Obtém os N-Grams compartilhados\n",
        "def sharedNgrams(ng1, ng2):\n",
        "    \n",
        "  return list(set(ng1) & set(ng2))\n",
        "\n",
        "# Calcula a similaridade através dos N-Grams\n",
        "def nGramsSimilarity(ng1, ng2):\n",
        "    \n",
        "  # Obtém N-Grams únicos para cada palavra\n",
        "  ung1 = uniqueNgrams(ng1)\n",
        "  ung2 = uniqueNgrams(ng2)\n",
        "    \n",
        "  #Número de N-Grams únicos da palavra 1\n",
        "  A = len(ung1)\n",
        "  #Número de N-Grams únicos da palavra 2\n",
        "  B = len(ung2)\n",
        "  #Número de N-Grams compartilhados entre as palavras\n",
        "  C = len(sharedNgrams(ung1, ung2))\n",
        "    \n",
        "  return (2 * C) / (A + B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHa0n40pTaTm"
      },
      "source": [
        "nGramsSimilarity(extrair_ngrams_char(p1,2), extrair_ngrams_char(p2,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VFowjBnHivA"
      },
      "source": [
        "#### Exemplo - Construindo um **verificador ortográfico simples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7J_G_c9KaAR"
      },
      "source": [
        "# Lista contendo o dicionário de palavras válidas\n",
        "dicionario = ['beneficente','cumprimento', 'comprimento', 'tráfego', 'tráfico', 'iminente', 'eminente', 'descrição', 'discrição']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28Z5JxbEMJ4K"
      },
      "source": [
        "# Função que verifica se palavra está no dicionário\n",
        "def verificar(p):\n",
        "  # Se palavra não está no dicionário\n",
        "  if p not in dicionario:\n",
        "\n",
        "    print(\"Palavra incorreta!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nkFhMHEKPyK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ceaa3755-4a72-4196-e449-2752d214d52a"
      },
      "source": [
        "#A seguir pediremos que o usuário digite uma palavra\n",
        "palavra = input(\"Digite uma palavra: \")\n",
        "\n",
        "# Verifica palavra informada pelo usuário\n",
        "verificar(palavra)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Digite uma palavra: teste\n",
            "Palavra incorreta!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFQobiPjN_M5"
      },
      "source": [
        "\n",
        "Re-implemente a função `verificar(p)` de modo que:\n",
        "1.  Caso a palavra digitada não exista no dicionário, ela sugira todas as outras que tenham uma distância de edição de valor 1 da palavra digitada. \n",
        "> **DICA**: Para percorrer a lista de palavras você pode utilizar o comando `for palavra in dicionario:`\n",
        "2.  Ao invés de receber apenas uma palavra, a função receba uma sentença inteira, faça a tokenização da mesma, e ofereça sugestões para todas palavras que nao se encontram no dicionário (caso as mesmas tenham distância de edição igual a 1)\n",
        "3. **BÔNUS**: Obter uma lista de palavras de maior abrangência, abrir arquivo e popular o dicionário (https://github.com/pythonprobr/palavras)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc0qL2PBGYLn"
      },
      "source": [
        "## Referências e Material complementar\n",
        "\n",
        "*   [Edit Distance & Jaccard](https://python.gotrained.com/nltk-edit-distance-jaccard-distance/)\n",
        "*   [N-Grams Tutorial](https://www.kaggle.com/rtatman/tutorial-getting-n-grams)\n",
        "*   [Introduction to N-Grams: What Are They and Why Do We Need Them?](https://blog.xrds.acm.org/2017/10/introduction-n-grams-need/)\n",
        "*   [Overview of Text Similarity metrics](https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50)\n",
        "\n"
      ]
    }
  ]
}